\begin{thebibliography}{22}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Caf()]{Caffe:CIFAR10}
Caffe {CIFAR-10} tutorial.
\newblock \url{http://caffe.berkeleyvision.org/gathered/examples/cifar10.html}.

\bibitem[Alistarh et~al.(2016)Alistarh, Li, Tomioka, and
  Vojnovic]{Alistarh:2016:ArXiv}
Alistarh, Dan, Li, Jerry, Tomioka, Ryota, and Vojnovic, Milan.
\newblock {QSGD: Randomized Quantization for Communication-Optimal Stochastic
  Gradient Descent}.
\newblock \emph{arXiv:1610.02132}, 2016.

\bibitem[Bubeck(2015)]{bubeck2015convex}
Bubeck, S{\'e}bastien.
\newblock Convex optimization: Algorithms and complexity.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  2015.

\bibitem[Cortes et~al.(2010)Cortes, Mohri, and Talwalkar]{Cortes:2010:AISTATS}
Cortes, Corinna, Mohri, Mehryar, and Talwalkar, Ameet.
\newblock On the impact of kernel approximation on learning accuracy.
\newblock In \emph{AISTATS}, 2010.

\bibitem[De~Sa et~al.(2015)De~Sa, Zhang, Olukotun, and R\'{e}]{DeSa:NIPS:2015}
De~Sa, Christopher~M, Zhang, Ce, Olukotun, Kunle, and R\'{e}, Christopher.
\newblock Taming the wild: A unified analysis of hogwild-style algorithms.
\newblock In \emph{NIPS}, 2015.

\bibitem[Gong et~al.(2014)Gong, Liu, Yang, and Bourdev]{gong2014compressing}
Gong, Yunchao, Liu, Liu, Yang, Ming, and Bourdev, Lubomir.
\newblock Compressing deep convolutional networks using vector quantization.
\newblock \emph{arXiv:1412.6115}, 2014.

\bibitem[Gopi et~al.(2013)Gopi, Netrapalli, Jain, and Nori]{Gopi:2013:ICML}
Gopi, Sivakant, Netrapalli, Praneeth, Jain, Prateek, and Nori, Aditya.
\newblock One-bit compressed sensing: Provable support and vector recovery.
\newblock In \emph{ICML}, 2013.

\bibitem[Gupta et~al.(2015)Gupta, Agrawal, Gopalakrishnan, and
  Narayanan]{gupta2015deep}
Gupta, Suyog, Agrawal, Ankur, Gopalakrishnan, Kailash, and Narayanan, Pritish.
\newblock Deep learning with limited numerical precision.
\newblock In \emph{ICML}, 2015.

\bibitem[Hall(2008)]{Hall:2008:Book}
Hall, Daniel~B.
\newblock Measurement error in nonlinear models: A modern perspective (2nd
  ed.).
\newblock \emph{Journal of the American Statistical Association}, 2008.

\bibitem[Han et~al.(2016)Han, Mao, and Dally]{Han:2016:ICLR}
Han, Song, Mao, Huizi, and Dally, William~J.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock In \emph{ICLR}, 2016.

\bibitem[Hubara et~al.(2016)Hubara, Courbariaux, Soudry, El-Yaniv, and
  Bengio]{hubara2016quantized}
Hubara, Itay, Courbariaux, Matthieu, Soudry, Daniel, El-Yaniv, Ran, and Bengio,
  Yoshua.
\newblock Quantized neural networks: Training neural networks with low
  precision weights and activations.
\newblock \emph{arXiv:1609.07061}, 2016.

\bibitem[Kim et~al.(2011)Kim, Zhang, and Fessler]{Kim:2011:ICASSP}
Kim, Jung~Kuk, Zhang, Zhengya, and Fessler, Jeffrey~A.
\newblock Hardware acceleration of iterative image reconstruction for x-ray
  computed tomography.
\newblock In \emph{ICASSP}, 2011.

\bibitem[Kim \& Smaragdis(2016)Kim and Smaragdis]{kim2016bitwise}
Kim, Minje and Smaragdis, Paris.
\newblock Bitwise neural networks.
\newblock \emph{arXiv:1601.06071}, 2016.

\bibitem[Kim et~al.(2015)Kim, Park, Yoo, Choi, Yang, and
  Shin]{kim2015compression}
Kim, Yong-Deok, Park, Eunhyeok, Yoo, Sungjoo, Choi, Taelim, Yang, Lu, and Shin,
  Dongjun.
\newblock Compression of deep convolutional neural networks for fast and low
  power mobile applications.
\newblock \emph{arXiv:1511.06530}, 2015.

\bibitem[Li et~al.(2016)Li, Zhang, and Liu]{li2016ternary}
Li, Fengfu, Zhang, Bo, and Liu, Bin.
\newblock Ternary weight networks.
\newblock \emph{arXiv:1605.04711}, 2016.

\bibitem[Lin et~al.(2016)Lin, Talathi, and Annapureddy]{lin2016fixed}
Lin, Darryl, Talathi, Sachin, and Annapureddy, Sreekanth.
\newblock Fixed point quantization of deep convolutional networks.
\newblock In \emph{ICML}, 2016.

\bibitem[Miyashita et~al.(2016)Miyashita, Lee, and
  Murmann]{miyashita2016convolutional}
Miyashita, Daisuke, Lee, Edward~H, and Murmann, Boris.
\newblock Convolutional neural networks using logarithmic data representation.
\newblock \emph{arXiv:1603.01025}, 2016.

\bibitem[Rastegari et~al.(2016)Rastegari, Ordonez, Redmon, and
  Farhadi]{rastegari2016xnor}
Rastegari, Mohammad, Ordonez, Vicente, Redmon, Joseph, and Farhadi, Ali.
\newblock Xnor-net: Imagenet classification using binary convolutional neural
  networks.
\newblock In \emph{ECCV}, 2016.

\bibitem[Seide et~al.(2014)Seide, Fu, Droppo, Li, and
  Yu]{Frank:2014:Interspeech}
Seide, Frank, Fu, Hao, Droppo, Jasha, Li, Gang, and Yu, Dong.
\newblock 1-bit stochastic gradient descent and application to data-parallel
  distributed training of speech dnns.
\newblock In \emph{Interspeech}, 2014.

\bibitem[Vanhoucke et~al.(2011)Vanhoucke, Senior, and
  Mao]{vanhoucke2011improving}
Vanhoucke, Vincent, Senior, Andrew, and Mao, Mark~Z.
\newblock Improving the speed of neural networks on cpus.
\newblock In \emph{NIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem[Wu et~al.(2016)Wu, Leng, Wang, Hu, and Cheng]{wu2016quantized}
Wu, Jiaxiang, Leng, Cong, Wang, Yuhang, Hu, Qinghao, and Cheng, Jian.
\newblock Quantized convolutional neural networks for mobile devices.
\newblock In \emph{CVPR}, 2016.

\bibitem[Zhou et~al.(2016)Zhou, Wu, Ni, Zhou, Wen, and Zou]{zhou2016dorefa}
Zhou, Shuchang, Wu, Yuxin, Ni, Zekun, Zhou, Xinyu, Wen, He, and Zou, Yuheng.
\newblock Dorefa-net: Training low bitwidth convolutional neural networks with
  low bitwidth gradients.
\newblock \emph{arXiv:1606.06160}, 2016.

\end{thebibliography}
